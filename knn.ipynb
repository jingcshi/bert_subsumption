{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AllenNLP not available. Registrable won't work.\n",
      "2022-08-11 23:00:45,841 - pykrylov.util.config [MainThread  ] [WARNI]  Add MMS_V1 entry to config clusters; No action needed on users' side\n",
      "2022-08-11 23:00:45,842 - pykrylov.util.config [MainThread  ] [WARNI]  Update MMS_V1 Server to https://krylov-mms.vip.ebay.com and ProxyServer to c2sproxy;No action needed on users' side\n",
      "Some weights of the model checkpoint at /data/ebay/notebooks/jingcshi/Curation/utils/bert/20220706-1751/ were not used when initializing EBertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing EBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pybay.bert import EBertModel, EBertTokenizer, EBertWordEmbedder, EBertForMaskedLM\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn import metrics\n",
    "from experiments import box_experiments, breadcrumb as bc\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from data import preprocess as prep\n",
    "from data.box_embedding import taxonomy_sampling\n",
    "from torch.utils.data import RandomSampler, DataLoader, Subset\n",
    "model = EBertWordEmbedder('/data/ebay/notebooks/jingcshi/Curation/utils/bert/20220706-1751/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breadcrumb_prep_m(br):\n",
    "    segs = br.replace(', ',' and ').replace('&','and').split(' > ')\n",
    "    shuffle(segs)\n",
    "    text = 'A category of products defined by: ' + segs[0]\n",
    "    if len(segs) > 1:\n",
    "        for s in segs[1:]:\n",
    "            text += ', '\n",
    "            text += s\n",
    "    return text + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breadcrumb_prep_k(br):\n",
    "    text = bc.keyword_string(br)\n",
    "    return 'A category of products defined by: '+ text + '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "catlist = prep.load_ebay_taxonomy({'data':{'raw_taxonomy_path': './data/2021-10-12', 'breadcrumb_link': 'id'}})\n",
    "with open ('/data/ebay/notebooks/jingcshi/Curation/leafcatid.txt') as f:\n",
    "    leafcats = f.readlines()\n",
    "for i,cat in enumerate(leafcats):\n",
    "    leafcats[i] = int(cat[:-1])\n",
    "breadcrumbs = prep.load_ebay_taxonomy({'data':{'raw_taxonomy_path': './data/2021-10-12', 'breadcrumb_link': 'symbol'}})\n",
    "breadcrumb_table = {}\n",
    "for _,(cid,br) in enumerate(breadcrumbs):\n",
    "    breadcrumb_table[int(cid)] = br\n",
    "df = pd.read_csv(\"./data/items/itemdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catid</th>\n",
       "      <th>itemid</th>\n",
       "      <th>itemtitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162925</td>\n",
       "      <td>125331554484</td>\n",
       "      <td>Set Of (2) 1800's Antique CHESTNUT BALUSTERS H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162925</td>\n",
       "      <td>193423296027</td>\n",
       "      <td>Antique Turned Wood Pine Spindle Baluster  26\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162925</td>\n",
       "      <td>173239007414</td>\n",
       "      <td>Wooden stairs Baluster Decor, unique carved  g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162925</td>\n",
       "      <td>304497204556</td>\n",
       "      <td>Buyers Products LB8133 Primed Steel Triple Ova...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162925</td>\n",
       "      <td>255241591207</td>\n",
       "      <td>Vtg Barley Twist Balusters Stair Railing Turne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392193</th>\n",
       "      <td>131542</td>\n",
       "      <td>174814914005</td>\n",
       "      <td>Pioneer BDR-207MBK 12x Blu-Ray BD-R Internal D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392194</th>\n",
       "      <td>131542</td>\n",
       "      <td>264395083337</td>\n",
       "      <td>HP DVD/CD Rewritable Drive DS-8ABSH 460510-800...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392195</th>\n",
       "      <td>131542</td>\n",
       "      <td>203961898030</td>\n",
       "      <td>LG - 8x External USB 2.0 Double-Layer DVD±RW/±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392196</th>\n",
       "      <td>131542</td>\n",
       "      <td>255546618319</td>\n",
       "      <td>Micro Advantage CD-ReWritable Drive 52x Write ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392197</th>\n",
       "      <td>131542</td>\n",
       "      <td>143992341088</td>\n",
       "      <td>661-3552 - Superdrive (Dvd+R DL, 16X) For Powe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6392198 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          catid        itemid  \\\n",
       "0        162925  125331554484   \n",
       "1        162925  193423296027   \n",
       "2        162925  173239007414   \n",
       "3        162925  304497204556   \n",
       "4        162925  255241591207   \n",
       "...         ...           ...   \n",
       "6392193  131542  174814914005   \n",
       "6392194  131542  264395083337   \n",
       "6392195  131542  203961898030   \n",
       "6392196  131542  255546618319   \n",
       "6392197  131542  143992341088   \n",
       "\n",
       "                                                 itemtitle  \n",
       "0        Set Of (2) 1800's Antique CHESTNUT BALUSTERS H...  \n",
       "1        Antique Turned Wood Pine Spindle Baluster  26\"...  \n",
       "2        Wooden stairs Baluster Decor, unique carved  g...  \n",
       "3        Buyers Products LB8133 Primed Steel Triple Ova...  \n",
       "4        Vtg Barley Twist Balusters Stair Railing Turne...  \n",
       "...                                                    ...  \n",
       "6392193  Pioneer BDR-207MBK 12x Blu-Ray BD-R Internal D...  \n",
       "6392194  HP DVD/CD Rewritable Drive DS-8ABSH 460510-800...  \n",
       "6392195  LG - 8x External USB 2.0 Double-Layer DVD±RW/±...  \n",
       "6392196  Micro Advantage CD-ReWritable Drive 52x Write ...  \n",
       "6392197  661-3552 - Superdrive (Dvd+R DL, 16X) For Powe...  \n",
       "\n",
       "[6392198 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(Q,embeds):\n",
    "    Q = torch.tensor(Q)\n",
    "    embeds = torch.tensor(embeds)\n",
    "    W = torch.softmax(torch.matmul(embeds,Q.view([-1,1])),dim=0)\n",
    "    return torch.cat((Q,torch.matmul(torch.t(W),embeds).reshape([-1]))).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_model(model,query_vec,inputs,batch_size):\n",
    "    if len(inputs) <= batch_size:\n",
    "        E = model.embed_raw_batch(inputs)\n",
    "        batch_embeddings = []\n",
    "        for e in E:\n",
    "            batch_embeddings.append(attention(query_vec,e.word_embedding[1:-1]))\n",
    "        return np.array(batch_embeddings)\n",
    "    else:\n",
    "        head = inputs[:batch_size]\n",
    "        tail = inputs[batch_size:]\n",
    "        return np.concatenate((batch_model(model,query_vec,head,batch_size),batch_model(model,query_vec,tail,batch_size)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fe1d0e9c704aef94367186eab0f3f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4153/3356796866.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mquery_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbreadcrumb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'itemtitle'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcatid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4153/3832684107.py\u001b[0m in \u001b[0;36mbatch_model\u001b[0;34m(model, query_vec, inputs, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_raw_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbatch_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mbatch_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pybay/bert/models/ebert_word_embedder.py\u001b[0m in \u001b[0;36membed_raw_batch\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membed_raw_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWordEmbeddingResult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_raw_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_test_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_case\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTestCase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pybay/bert/models/ebert_word_embedder.py\u001b[0m in \u001b[0;36membed_raw_minibatch\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membed_raw_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWordEmbeddingResult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membed_raw_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWordEmbeddingResult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pybay/bert/models/ebert_word_embedder.py\u001b[0m in \u001b[0;36m_impl\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mbatch_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mword_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0msentence_embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             )\n\u001b[1;32m     77\u001b[0m         ]\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pybay/bert/models/ebert_word_embedder.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mword_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             sentence_embedding=s_emb)\n\u001b[0;32m---> 71\u001b[0;31m             for sentence, tok, w_emb, s_emb in zip(\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0moutput_sentences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mbatch_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pydantic/main.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pydantic/main.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.main.validate_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pydantic/fields.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.fields.ModelField.validate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pydantic/fields.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.fields.ModelField._apply_validators\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pydantic/class_validators.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mpydantic.class_validators._generic_validator_basic.lambda12\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pybay/types/nlp/embedding/sentence_embedding_result.py\u001b[0m in \u001b[0;36m_validate_sentence_embedding\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m\"\"\" A numpy array of a sentence embedding. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mvalidator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sentence_embedding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_sentence_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 500\n",
    "embeddings = {}\n",
    "with tqdm(total=len(leafcats)) as pbar:\n",
    "    for catid in leafcats:\n",
    "        df_cat = df[df['catid'] == catid]\n",
    "        if df_cat.empty:\n",
    "            embeddings[catid] = np.empty([0,1536])\n",
    "        else:\n",
    "            breadcrumb = breadcrumb_prep_k(breadcrumb_table[catid])\n",
    "            query_vec = model.embed_raw(breadcrumb).sentence_embedding\n",
    "            titles = list(df_cat['itemtitle'].dropna())\n",
    "            outputs = batch_model(model,query_vec,titles,BATCH_SIZE)\n",
    "            embeddings[catid] = outputs\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/data/ebay/data/jingcshi/item_embeddings_5.json', 'w') as outf:\n",
    "    #outf.write(json.dumps(embeddings_json))\n",
    "#embeddings = pd.read_csv('/data/ebay/data/jingcshi/item_embeddings_7.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cattree = {}\n",
    "for (cid,cpath) in catlist:\n",
    "    cattree[int(cid)] = set()\n",
    "    cpath = cpath.split(' ')\n",
    "    if len(cpath) > 1:\n",
    "        parent = cpath[-2]\n",
    "        cattree[int(parent)].add(int(cid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "leaflist = list(embeddings.keys())\n",
    "cluster_tree = {}\n",
    "for c in list(cattree.keys()):\n",
    "    cluster_tree[int(c)] = None\n",
    "for l in leaflist:\n",
    "    cluster_tree[int(l)] = embeddings[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dp(cat):\n",
    "    if cluster_tree[cat] is None:\n",
    "        if cattree[cat] == set():\n",
    "            cluster_tree[cat] == np.empty([0,1536])\n",
    "            return 0\n",
    "        else:\n",
    "            for child in cattree[cat]:\n",
    "                if cluster_tree[child] is None:\n",
    "                    dp(child)\n",
    "            '''        \n",
    "            try:\n",
    "                cluster_tree[cat] = np.concatenate([cluster_tree[child] for child in cattree[cat]])\n",
    "            except ValueError:\n",
    "                print(f'Category: {cat}')\n",
    "                for child in cattree[cat]:\n",
    "                    print(f'Child: {child}\\n{cluster_tree[child]}')\n",
    "            return 0\n",
    "            '''\n",
    "            cluster_tree[cat] = np.concatenate([cluster_tree[child] for child in cattree[cat]])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "L = list(cluster_tree.keys())\n",
    "for i in tqdm(range(len(L))):\n",
    "    c = L[i]\n",
    "    dp(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D0 = 1\n",
    "C = 0.9\n",
    "DOWNSAMPLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neighbours = {}\n",
    "for i in tqdm(range(len(L))):\n",
    "    base_cat = L[i]\n",
    "    base = cluster_tree[base_cat]\n",
    "    if base.shape[0] > 0:\n",
    "        neighbours[base_cat] = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "        neighbours[base_cat].fit(cluster_tree[base_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_cat = 175781\n",
    "base_cat = 15687\n",
    "base_cat_name = breadcrumb_table[base_cat]\n",
    "query_cat_name = breadcrumb_table[query_cat]\n",
    "query = cluster_tree[query_cat]\n",
    "n_items = query.shape[0]\n",
    "if n_items > 1000 and DOWNSAMPLE:\n",
    "    query = query[np.random.choice(n_items, 1000, replace=False)]\n",
    "dist, _ = neighbours[base_cat].kneighbors(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_items = np.sum(dist <= D0)\n",
    "total_items = query.shape[0]\n",
    "pred_score = pos_items / total_items\n",
    "pred = pred_score >= C\n",
    "print(f'Parent: {base_cat} ({base_cat_name})\\nChild: {query_cat} ({query_cat_name})\\nSubclass prediction: {pred}\\nPrediction score: {pos_items}/{total_items} = {pred_score:.3f}\\nDistance table:\\n{dist}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(df[df['catid'] == 175781]['itemtitle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breadcrumb:\n",
      "\tA category of products defined by: vintage, accessory, specialty, t-shirt, men, shoe.\n",
      "Items title:\n",
      "\tORIGINAL KAWASAKI T-SHIRT IRON-ON VINTAGE 70s UNUSED TRANSFER\n",
      "Attention weights:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original</th>\n",
       "      <td>0.097459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kawasaki</th>\n",
       "      <td>0.076623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>0.073301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>0.068436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shirt</th>\n",
       "      <td>0.098338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iron</th>\n",
       "      <td>0.078063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>0.070489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>On</th>\n",
       "      <td>0.083561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vintage</th>\n",
       "      <td>0.105993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70s</th>\n",
       "      <td>0.083010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNUSED</th>\n",
       "      <td>0.084260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transer</th>\n",
       "      <td>0.080468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Weights\n",
       "Original  0.097459\n",
       "Kawasaki  0.076623\n",
       "T         0.073301\n",
       "-         0.068436\n",
       "Shirt     0.098338\n",
       "Iron      0.078063\n",
       "-         0.070489\n",
       "On        0.083561\n",
       "Vintage   0.105993\n",
       "70s       0.083010\n",
       "UNUSED    0.084260\n",
       "Transer   0.080468"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "catid = 175781\n",
    "breadcrumb = breadcrumb_prep_k(breadcrumb_table[catid])\n",
    "Q = model.embed_raw(breadcrumb).sentence_embedding\n",
    "item = \"ORIGINAL KAWASAKI T-SHIRT IRON-ON VINTAGE 70s UNUSED TRANSFER\" #random.sample(list(df[df['catid'] == catid]['itemtitle']),1)[0]\n",
    "embeds = model.embed_raw(item)\n",
    "Q = torch.tensor(Q)\n",
    "E = torch.tensor(embeds.word_embedding[1:-1])\n",
    "W = torch.softmax(torch.matmul(E,Q.view([-1,1])),dim=0).view([-1])\n",
    "print(f'Breadcrumb:\\n\\t{breadcrumb}\\nItems title:\\n\\t{item}\\nAttention weights:')\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "n = E.shape[0]\n",
    "x = 0.5 + np.arange(n)\n",
    "y = W.numpy()\n",
    "'''\n",
    "wmax = np.max(y)\n",
    "ax.bar(x, y, width=1, edgecolor=\"white\", linewidth=0.7, color=[(0,0,1,0.5*(w/wmax)**2) for w in y])\n",
    "ax.set_xlim((0,n))\n",
    "ax.set_xticks(0.5+np.arange(n),labels=embeds.tokens[1:-1],fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "'''\n",
    "weights = pd.DataFrame({'Weights': y}, index=['Original','Kawasaki','T','-','Shirt','Iron','-','On','Vintage','70s','UNUSED','Transer'])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.read_csv('./data/test/subclass_golden_set.csv').dropna()\n",
    "validcats = list(cluster_tree.keys())\n",
    "for i,row in testdata.iterrows():\n",
    "    if row['cat1'] not in validcats or row['cat2'] not in validcats:\n",
    "        testdata = testdata.drop([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a402e0c78e59456387167535a2fba3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">F1=0.6265, precision=0.5474, recall=0.7324</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Predict subsumption</th>\n",
       "      <th>Predict negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Label subsumption</th>\n",
       "      <td>52</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label negative</th>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  F1=0.6265, precision=0.5474, recall=0.7324                 \n",
       "                                         Predict subsumption Predict negative\n",
       "Label subsumption                                         52               19\n",
       "label negative                                            43               14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>label_loose</th>\n",
       "      <th>label_strict</th>\n",
       "      <th>prediction</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13756</td>\n",
       "      <td>261979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13756</td>\n",
       "      <td>261981</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13756</td>\n",
       "      <td>261983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13756</td>\n",
       "      <td>261984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261979</td>\n",
       "      <td>261983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>22966</td>\n",
       "      <td>118985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>261658</td>\n",
       "      <td>32884</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>118985</td>\n",
       "      <td>33034</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>262366</td>\n",
       "      <td>36028</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>50129</td>\n",
       "      <td>262421</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cat1    cat2  label_loose  label_strict  prediction  score\n",
       "0     13756  261979            0             0           1  1.000\n",
       "1     13756  261981            0             0           1  0.994\n",
       "2     13756  261983            0             0           1  1.000\n",
       "3     13756  261984            0             0           1  1.000\n",
       "4    261979  261983            0             0           1  0.998\n",
       "..      ...     ...          ...           ...         ...    ...\n",
       "131   22966  118985            0             0           1  1.000\n",
       "132  261658   32884            1             0           1  1.000\n",
       "133  118985   33034            1             1           1  1.000\n",
       "134  262366   36028            1             0           1  1.000\n",
       "135   50129  262421            1             1           0  0.000\n",
       "\n",
       "[128 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "confusion = {'y': np.array([],dtype=np.int32), 'y_pred': np.array([])}\n",
    "with tqdm(total=testdata.shape[0]) as bar:\n",
    "    for _, row in testdata.iterrows():\n",
    "        confusion['y'] = np.append(confusion['y'], row['label_loose'])\n",
    "        query = cluster_tree[row['cat1']]\n",
    "        n_items = query.shape[0]\n",
    "        if n_items > 1000 and DOWNSAMPLE:\n",
    "            query = query[np.random.choice(n_items, 1000, replace=False)]\n",
    "        dist, _ = neighbours[row['cat2']].kneighbors(query)\n",
    "        pos_items = np.sum(dist <= D0)\n",
    "        total_items = query.shape[0]\n",
    "        pred_score = pos_items / total_items\n",
    "        confusion['y_pred'] = np.append(confusion['y_pred'], (pred_score >= C))\n",
    "        predictions.append(pred_score)\n",
    "        bar.update(1)\n",
    "testresult = testdata\n",
    "testresult['prediction'] = [int(p >= C) for p in predictions]\n",
    "testresult['score'] = predictions\n",
    "test_cm = box_experiments.build_confusion_matrix(confusion)\n",
    "print(f'Test results:')\n",
    "display(test_cm)\n",
    "display(testresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403762b733984054a01c46e211d02a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16888 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:263: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims, where=where)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in true_divide\n",
      "  subok=False)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:252: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    }
   ],
   "source": [
    "features = {}\n",
    "features_json = {}\n",
    "for i in tqdm(range(len(L))):\n",
    "    c = L[i]\n",
    "    cluster = cluster_tree[c]\n",
    "    mean = np.mean(cluster,axis=0)\n",
    "    std = np.std(cluster,axis=0)\n",
    "    feature = np.concatenate((mean,std),axis=None)\n",
    "    features[c] = feature\n",
    "    features_json[c] = feature.tolist()\n",
    "with open('/data/ebay/data/jingcshi/features_8.json', 'w') as f:\n",
    "    f.write(json.dumps(features_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments\n",
      "experiments.breadcrumb\n",
      "experiments.box_experiments\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "package_name = 'experiments'\n",
    "loaded_package_modules = [key for key, value in sys.modules.items() if package_name in str(value)]\n",
    "for key in loaded_package_modules:\n",
    "        print(key)\n",
    "        del sys.modules[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /data/ebay/data/jingcshi/.pybay_cache/e6f108c7-44e2-49cc-9809-78dfdfa0eb1f were not used when initializing EBertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing EBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "maskmodel = EBertForMaskedLM.from_pretrained('eBERT-multilingual-base-2020Q3-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
